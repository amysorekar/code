{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db835bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BENCHMARK RESULTS (role = analyst ) ---\n",
      "{\n",
      "  \"question\": \"Can you tell me what year it is?\",\n",
      "  \"user_response\": \"uhh twenny twenty two i think\",\n",
      "  \"function_called\": \"record_orientation_time\",\n",
      "  \"arguments\": {\n",
      "    \"date\": \"2022\"\n",
      "  },\n",
      "  \"expected_function\": \"record_orientation_time\",\n",
      "  \"correct_function\": true,\n",
      "  \"token_usage\": 2669,\n",
      "  \"latency\": 1.5022023926841006,\n",
      "  \"pii_detected\": false\n",
      "}\n",
      "{\n",
      "  \"question\": \"Have you had any issues with your memory?\",\n",
      "  \"user_response\": \"Sometimes I forget my phone number <PII:3c95277da5> and even my name <PII:6cea57c2fb>.\",\n",
      "  \"function_called\": \"record_orientation_time\",\n",
      "  \"arguments\": {\n",
      "    \"date\": \"incorrect\"\n",
      "  },\n",
      "  \"expected_function\": \"record_memory_issue\",\n",
      "  \"correct_function\": false,\n",
      "  \"token_usage\": 1870,\n",
      "  \"latency\": 1.67927035223505,\n",
      "  \"pii_detected\": true\n",
      "}\n",
      "{\n",
      "  \"question\": \"Have you thought about hurting yourself?\",\n",
      "  \"user_response\": \"yeah lately I've had dark thoughts\",\n",
      "  \"function_called\": \"flag_self_harm\",\n",
      "  \"arguments\": {\n",
      "    \"severity\": \"moderate\"\n",
      "  },\n",
      "  \"expected_function\": \"flag_self_harm\",\n",
      "  \"correct_function\": true,\n",
      "  \"token_usage\": 2949,\n",
      "  \"latency\": 1.0371654431929465,\n",
      "  \"pii_detected\": false\n",
      "}\n",
      "\n",
      "--- ALERTS ---\n",
      "ALERT: Function fail rate 33.33% exceeds threshold\n",
      "ALERT: P95 latency 1.50s exceeds threshold\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import hashlib\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "# Config\n",
    "function_schema = {\n",
    "    \"record_orientation_time\": {\n",
    "        \"description\": \"Records patient's response to time-related question\",\n",
    "        \"parameters\": {\"date\": \"str\"}\n",
    "    },\n",
    "    \"record_memory_issue\": {\n",
    "        \"description\": \"Logs a memory-related response\",\n",
    "        \"parameters\": {\"description\": \"str\"}\n",
    "    },\n",
    "    \"flag_self_harm\": {\n",
    "        \"description\": \"Flags potential self‑harm intent\",\n",
    "        \"parameters\": {\"severity\": \"str\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "alert_thresholds = {\n",
    "    \"token_usage\": 3000,\n",
    "    \"function_fail_rate\": 0.10,\n",
    "    \"call_fail_rate\": 0.20,\n",
    "    \"latency_p95_threshold\": 1.5,\n",
    "    \"critical_failure\": True\n",
    "}\n",
    "\n",
    "# Role‑based redaction rules\n",
    "authorized_roles = {\n",
    "    \"admin\": {\"can_view_pii\": True},\n",
    "    \"analyst\": {\"can_view_pii\": False}\n",
    "}\n",
    "current_role = \"analyst\"  # change to \"admin\" to view full logs\n",
    "\n",
    "\n",
    "\n",
    "PII_PATTERNS = [\n",
    "    re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"),         # SSN\n",
    "    re.compile(r\"\\b\\d{10}\\b\"),                    # phone number\n",
    "    re.compile(r\"\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b\")   # simple First Last name\n",
    "]\n",
    "\n",
    "def detect_and_redact_pii(text: str) -> Dict[str, str]:\n",
    "    \"\"\"Detect PII and return dict with redacted or hashed output.\"\"\"\n",
    "    redacted = text\n",
    "    pii_found = False\n",
    "    for pattern in PII_PATTERNS:\n",
    "        matches = pattern.findall(text)\n",
    "        for m in matches:\n",
    "            pii_found = True\n",
    "            hashed = hashlib.sha256(m.encode()).hexdigest()[:10]  # short hash\n",
    "            redacted = redacted.replace(m, f\"<PII:{hashed}>\")\n",
    "    return {\"text\": redacted, \"pii\": pii_found}\n",
    "\n",
    "# Mock LLM because we can't call a real one here\n",
    "def mock_llm(convo):\n",
    "    \"\"\"Return simulated latency, token usage and function call.\"\"\"\n",
    "    latency = random.uniform(0.3, 2.0)\n",
    "    time.sleep(latency * 0.02)\n",
    "    token_usage = random.randint(500, 3500)\n",
    "\n",
    "    critical = convo[\"difficulty\"] == \"critical\"\n",
    "    success_prob = 0.95 if critical else 0.8\n",
    "    correct = random.random() < success_prob\n",
    "\n",
    "    if correct:\n",
    "        fn_name = convo[\"expected_function\"]\n",
    "        fn_args = convo[\"expected_args\"]\n",
    "    else:\n",
    "        fn_name = random.choice([f for f in function_schema if f != convo[\"expected_function\"]])\n",
    "        fn_args = {k: \"incorrect\" for k in function_schema[fn_name][\"parameters\"]}\n",
    "\n",
    "    return {\n",
    "        \"latency\": latency,\n",
    "        \"token_usage\": token_usage,\n",
    "        \"function_call\": {\"name\": fn_name, \"arguments\": fn_args}\n",
    "    }\n",
    "\n",
    "\n",
    "# Benchmarking\n",
    "audit_log: List[Dict] = []\n",
    "alerts: List[str] = []\n",
    "all_latencies: List[float] = []\n",
    "fail_counts = {\"func\": 0, \"call\": 0}\n",
    "critical_failure = False\n",
    "\n",
    "# Simulated conversations\n",
    "conversations = [\n",
    "    {\n",
    "        \"question\": \"Can you tell me what year it is?\",\n",
    "        \"user_response\": \"uhh twenny twenty two i think\",\n",
    "        \"expected_function\": \"record_orientation_time\",\n",
    "        \"expected_args\": {\"date\": \"2022\"},\n",
    "        \"difficulty\": \"medium\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Have you had any issues with your memory?\",\n",
    "        \"user_response\": \"Sometimes I forget my phone number 5551234567 and even my name John Doe.\",\n",
    "        \"expected_function\": \"record_memory_issue\",\n",
    "        \"expected_args\": {\"description\": \"forgets phone number\"},\n",
    "        \"difficulty\": \"medium\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Have you thought about hurting yourself?\",\n",
    "        \"user_response\": \"yeah lately I've had dark thoughts\",\n",
    "        \"expected_function\": \"flag_self_harm\",\n",
    "        \"expected_args\": {\"severity\": \"moderate\"},\n",
    "        \"difficulty\": \"critical\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for convo in conversations:\n",
    "    # Detect and redact PII in user response before processing/logging\n",
    "    pii_check = detect_and_redact_pii(convo[\"user_response\"])\n",
    "    processed_response = pii_check[\"text\"]\n",
    "\n",
    "    result = mock_llm(convo)\n",
    "\n",
    "    latency = result[\"latency\"]\n",
    "    all_latencies.append(latency)\n",
    "\n",
    "    fn_name = result[\"function_call\"][\"name\"]\n",
    "    fn_args = result[\"function_call\"][\"arguments\"]\n",
    "    token_usage = result[\"token_usage\"]\n",
    "\n",
    "    correct_fn = fn_name == convo[\"expected_function\"]\n",
    "    correct_args = fn_args == convo[\"expected_args\"]\n",
    "\n",
    "    if not correct_fn:\n",
    "        fail_counts[\"func\"] += 1\n",
    "        if convo[\"difficulty\"] == \"critical\":\n",
    "            critical_failure = True\n",
    "\n",
    "    if not fn_name:\n",
    "        fail_counts[\"call\"] += 1\n",
    "\n",
    "    # Store a redacted view if role forbids PII\n",
    "    log_entry = {\n",
    "        \"question\": convo[\"question\"],\n",
    "        \"user_response\": processed_response if not authorized_roles[current_role][\"can_view_pii\"] else convo[\"user_response\"],\n",
    "        \"function_called\": fn_name,\n",
    "        \"arguments\": fn_args,\n",
    "        \"expected_function\": convo[\"expected_function\"],\n",
    "        \"correct_function\": correct_fn,\n",
    "        \"token_usage\": token_usage,\n",
    "        \"latency\": latency,\n",
    "        \"pii_detected\": pii_check[\"pii\"]\n",
    "    }\n",
    "    audit_log.append(log_entry)\n",
    "\n",
    "    if token_usage > alert_thresholds[\"token_usage\"]:\n",
    "        alerts.append(f\"High token usage: {token_usage} tokens\")\n",
    "\n",
    "# Metrics and alerts\n",
    "func_fail_rate = fail_counts[\"func\"] / len(conversations)\n",
    "call_fail_rate = fail_counts[\"call\"] / len(conversations)\n",
    "p95_latency = sorted(all_latencies)[int(len(all_latencies)*0.95)-1]\n",
    "\n",
    "if func_fail_rate > alert_thresholds[\"function_fail_rate\"]:\n",
    "    alerts.append(f\"Function fail rate {func_fail_rate:.2%} exceeds threshold\")\n",
    "if call_fail_rate > alert_thresholds[\"call_fail_rate\"]:\n",
    "    alerts.append(f\"Call fail rate {call_fail_rate:.2%} exceeds threshold\")\n",
    "if p95_latency > alert_thresholds[\"latency_p95_threshold\"]:\n",
    "    alerts.append(f\"P95 latency {p95_latency:.2f}s exceeds threshold\")\n",
    "if critical_failure and alert_thresholds[\"critical_failure\"]:\n",
    "    alerts.append(\"CRITICAL: Missed self-harm detection\")\n",
    "\n",
    "print(\"--- BENCHMARK RESULTS (role =\", current_role, \") ---\")\n",
    "for entry in audit_log:\n",
    "    print(json.dumps(entry, indent=2))\n",
    "\n",
    "print(\"\\n--- ALERTS ---\")\n",
    "for a in alerts:\n",
    "    print(\"ALERT:\", a)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
